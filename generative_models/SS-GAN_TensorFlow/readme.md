# Tensorflow Implementation of Semi Supervised GAN

## Usage
```bash
$ python3 main.py 
```

> **_NOTE:_** on Colab Notebook use following command:
```python
!git clone --link-to-repo
!python main.py
```
```
usage: main.py [-h] [--epochs EPOCHS] [--latent_dim LATENT_DIM] [--lr LR]
               [--dropout DROPOUT] [--beta_1 BETA_1] [--alpha ALPHA]

optional arguments:
  -h, --help            show this help message and exit
  --epochs EPOCHS       No of epochs: default 20
  --latent_dim LATENT_DIM
                        Dimension of latent vector , default 100
  --lr LR               Learning rate : default 0.0002
  --dropout DROPOUT     Dropout, default 0.4
  --beta_1 BETA_1       beta_1 : default 0.5
  --alpha ALPHA         alpha : default 0.2
```
## Contributed by:
* [Antreev Singh Brar](https://github.com/antreev-brar)
## References

* **Title**: Semi-Supervised Learning with Generative Adversarial Networks
* **Authors**: Augustus Odena
* **Link**: https://arxiv.org/abs/1606.01583
* **Tags**: Neural Network , GAN
* **Year**: 2016

# Summary

## Why new Model(Drawbacks of YOLOv1 and YOLOv2)

* YOLOv1 imposes strong spatial constraints on bounding box predictions since each grid cell only predicts two boxes and can only have one class. This spatial constraint limits the number of nearby objects that our model can predict. Model struggles with small objects that appear in groups, such as flocks of birds. Since the model learns to predict bounding boxes from data, it struggles to generalize to objects in new or unusual aspect ratios or configurations.  Model also uses relatively coarse features for predicting bounding boxes since their architecture has multiple downsampling layers from the input image. Finally, while  train on a loss function that approximates detection performance, their loss function treats errors the same in small bounding boxes versus large bounding boxes. A small error in a large box is generally benign but a small error in a small box has a much greater effect on IOU. The main source of error is incorrect localizations
* YOLO v2 used a custom deep architecture darknet-19, an originally 19-layer network supplemented with 11 more layers for object detection. With a 30-layer architecture, YOLO v2 often struggled with small object detections. This was attributed to loss of fine-grained features as the layers downsampled the input.YOLO v2â€™s architecture was still lacking some of the most important elements that are now staple in most of state-of-the art algorithms. No residual blocks, no skip connections and no upsampling. YOLO v2 used softmax for class prediction which isn't the most suitable choice .
## Introduction 
Main purpose of a object detector is to be fast and accurate and able to recognize wide dataset.


## Key features of YOLOv3
### Bounding Box
 - It is same as that used in Previous versions . Cordinates are predicted and sum of squared error loss is used while training
- Objectness score is predicted using logistic regression

### Class Prediction
- Softmax is not used.
- Independent logistic classifiers are used and binary cross-entropy loss is used

### Prediction on different scales
- As my personal opinion it is the best feature of YOLOv3 , it predicts bounding boxes on 3 different scales for detection on different scales . Previous versions used just one .
- k-means clustering is used here as well to find better bounding box prior but this version used predefined anchor box dimensions.
- Darknet - 53 feature extractor is used which is much deeper than Darknet- 19 used in YOLO v2


### Model Summary
![4](./assets/architecture.png)
```
Total params: 62,001,757
Trainable params: 61,949,149
Non-trainable params: 52,608
```


## What happens in the Background 


## Result
These are fake digits generated by GAN
![4](./assets/fake_gen.png)

Graphs :
![4](./assets/loss.png)
![4](./assets/test_acc.png)
![4](./assets/train_acc.png)
